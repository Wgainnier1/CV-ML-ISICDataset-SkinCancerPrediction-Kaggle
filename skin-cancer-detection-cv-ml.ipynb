{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":63056,"databundleVersionId":9094797,"sourceType":"competition"},{"sourceId":9252973,"sourceType":"datasetVersion","datasetId":5598090},{"sourceId":9260623,"sourceType":"datasetVersion","datasetId":5603366},{"sourceId":101942,"sourceType":"modelInstanceVersion","modelInstanceId":85465,"modelId":109691}],"dockerImageVersionId":30761,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Skin cancer detection","metadata":{}},{"cell_type":"markdown","source":"Loading of torcheval library","metadata":{}},{"cell_type":"code","source":"!pip install torcheval --no-index --find-links=file:///kaggle/input/torcheval/torcheval","metadata":{"execution":{"iopub.status.busy":"2024-08-29T09:24:06.724391Z","iopub.execute_input":"2024-08-29T09:24:06.724878Z","iopub.status.idle":"2024-08-29T09:24:20.915332Z","shell.execute_reply.started":"2024-08-29T09:24:06.724835Z","shell.execute_reply":"2024-08-29T09:24:20.914222Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Looking in links: file:///kaggle/input/torcheval/torcheval\nProcessing /kaggle/input/torcheval/torcheval/torcheval-0.0.7-py3-none-any.whl\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torcheval) (4.12.2)\nInstalling collected packages: torcheval\nSuccessfully installed torcheval-0.0.7\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Loading of CV Model trained before on dataset of training","metadata":{}},{"cell_type":"code","source":"import numpy as np, pandas as pd, polars as pl\nfrom colorama import Fore, Back, Style\nimport os\nfrom sklearn.metrics import roc_curve, auc\nimport h5py\nfrom sklearn.model_selection import train_test_split\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom imblearn.pipeline import Pipeline\nfrom imblearn.over_sampling import RandomOverSampler\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.ensemble import VotingClassifier\nimport lightgbm as lgb, catboost as cb, xgboost as xgb\nimport io\nimport albumentations as A\nimport torchvision.transforms as transform\nfrom PIL import Image \nimport gc\nimport cv2\nimport math\nimport copy\nimport time\nimport random\nimport glob\nfrom matplotlib import pyplot as plt\nfrom pathlib import Path\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.cuda import amp\nimport torchvision\nfrom torcheval.metrics.functional import binary_auroc\nimport joblib\nfrom tqdm import tqdm\nfrom collections import defaultdict\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import StratifiedKFold, StratifiedGroupKFold \nimport timm\n# Albumentations for augmentations\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n# For colored terminal text\nfrom colorama import Fore, Back, Style\nimport warnings\nimport glob\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\nb_ = Fore.BLUE\nsr_ = Style.RESET_ALL\nos.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n\nROOT_DIR = \"/kaggle/input/isic-2024-challenge\"\nTEST_DIR = f'{ROOT_DIR}/test-image.hdf5'\ntest_images = sorted(glob.glob(f\"{TEST_DIR}/*.jpg\"))\ndf_test = pd.read_csv(f\"{ROOT_DIR}/test-metadata.csv\")\n\ndef get_filepath(image_id):\n    return f\"{TEST_DIR}/{image_id}.jpg\"\n\nclass SkinCancerNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(3, 16, 5)\n        self.bn1 = nn.BatchNorm2d(16)\n        self.pool = nn.MaxPool2d(2, 2)\n\n        self.conv2 = nn.Conv2d(16, 32, 5)\n        self.bn2 = nn.BatchNorm2d(32)\n\n        self.conv3 = nn.Conv2d(32, 64, 3)\n        self.bn3 = nn.BatchNorm2d(64)\n\n        self.conv4 = nn.Conv2d(64, 128, 3)\n        self.bn4 = nn.BatchNorm2d(128)\n\n        # Calculate the size of the feature map after the conv and pool layers\n        # Input size: 128x128\n        # After conv1: (128 - 5 + 1) = 124 -> 124x124\n        # After pool1: 124 / 2 = 62 -> 62x62\n        # After conv2: (62 - 5 + 1) = 58 -> 58x58\n        # After pool2: 58 / 2 = 29 -> 29x29\n        # After conv3: (29 - 3 + 1) = 27 -> 27x27\n        # After pool3: 27 / 2 = 13.5 -> 13x13 (rounding down)\n        # After conv4: (13 - 3 + 1) = 11 -> 11x11\n        # After pool4: 11 / 2 = 5.5 -> 5x5 (rounding down)\n\n        self.fc1 = nn.Linear(128 * 5 * 5, 512)\n        self.dropout1 = nn.Dropout(0.5)\n\n        self.fc2 = nn.Linear(512, 256)\n        self.dropout2 = nn.Dropout(0.5)\n\n        self.fc3 = nn.Linear(256, 128)\n        self.fc4 = nn.Linear(128, 1)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n        x = self.pool(F.relu(self.bn4(self.conv4(x))))\n\n        x = torch.flatten(x, 1)\n\n        x = F.relu(self.fc1(x))\n        x = self.dropout1(x)\n\n        x = F.relu(self.fc2(x))\n        x = self.dropout2(x)\n\n        x = F.relu(self.fc3(x))\n        x = torch.sigmoid(self.fc4(x))\n\n        return x\n    \n    \ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\nprint(\"Device:\", device)\n\nmodel = SkinCancerNet()\nmodel = model.to(device)\n\n# Load the model weights\nmodel.load_state_dict(torch.load('/kaggle/input/model/pytorch/default/1/my_model.pth'))\nmodel.eval() \n\nclass ISIC2024Dataset2(Dataset):\n    def __init__(self, metadata: pd.DataFrame, ids_images: dict, test: bool=False,transform = None):\n        self.metadata = metadata\n        self.fp_hdf = h5py.File(TEST_DIR, mode=\"r\")\n        self.ids_images = ids_images\n        self.test = test\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.metadata)\n\n    def __getitem__(self, item):\n        isic_row = self.metadata.iloc[item]\n        isic_id = isic_row.isic_id\n        image = Image.open(io.BytesIO(self.fp_hdf[isic_id][()]))\n        if self.transform:\n            image = self.transform(image=np.array(image))['image']\n        if self.test:\n            return image\n        return image\n    \n    \n\nids = set(df_test[\"isic_id\"])\ndef prepare_loaders2(df,ids):\n    data_transform  = A.Compose([\n        A.Resize(128, 128),\n        A.Normalize(\n                mean=[0.485, 0.456, 0.406], \n                std=[0.229, 0.224, 0.225], \n                max_pixel_value=255.0, \n                p=1.0\n            ),\n        ToTensorV2()], p=1.)\n    df = df.reset_index(drop=True)\n    valid_dataset = ISIC2024Dataset2(df,ids,transform = data_transform )\n    valid_loader = DataLoader(valid_dataset, batch_size=32, \n                             num_workers=2, shuffle=False, pin_memory=True)\n    return valid_loader\n\n\nvalid_loader  = prepare_loaders2(df_test,ids)","metadata":{"execution":{"iopub.status.busy":"2024-08-29T09:24:20.917318Z","iopub.execute_input":"2024-08-29T09:24:20.917639Z","iopub.status.idle":"2024-08-29T09:24:50.496505Z","shell.execute_reply.started":"2024-08-29T09:24:20.917604Z","shell.execute_reply":"2024-08-29T09:24:50.495662Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/albumentations/check_version.py:49: UserWarning: Error fetching version info <urlopen error [Errno -3] Temporary failure in name resolution>\n  data = fetch_version_info()\n","output_type":"stream"},{"name":"stdout","text":"Device: cuda:0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Prediction of the CV model on test data","metadata":{}},{"cell_type":"code","source":"all_probs = []\nwith torch.no_grad():\n     for i, data in enumerate(tqdm(valid_loader)):\n        inputs = data.to(device)\n         # calculate outputs by running images through the network\n        probs = model(inputs).flatten()\n        all_probs.extend(probs.cpu().tolist())\n         # the class with the highest energy is what we choose as prediction\n        predicted = (probs >= 0.5).float()\n        \ndf_test[\"pred\"] = all_probs","metadata":{"execution":{"iopub.status.busy":"2024-08-29T09:24:50.497538Z","iopub.execute_input":"2024-08-29T09:24:50.498044Z","iopub.status.idle":"2024-08-29T09:24:51.357994Z","shell.execute_reply.started":"2024-08-29T09:24:50.497986Z","shell.execute_reply":"2024-08-29T09:24:51.356938Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"100%|██████████| 1/1 [00:00<00:00,  1.18it/s]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Machine Learning","metadata":{}},{"cell_type":"markdown","source":"Feature engineering","metadata":{}},{"cell_type":"code","source":"num_cols = [\n    'age_approx',                        # Approximate age of patient at time of imaging.\n    'clin_size_long_diam_mm',            # Maximum diameter of the lesion (mm).+\n    'tbp_lv_A',                          # A inside  lesion.+\n    'tbp_lv_Aext',                       # A outside lesion.+\n    'tbp_lv_B',                          # B inside  lesion.+\n    'tbp_lv_Bext',                       # B outside lesion.+ \n    'tbp_lv_C',                          # Chroma inside  lesion.+\n    'tbp_lv_Cext',                       # Chroma outside lesion.+\n    'tbp_lv_H',                          # Hue inside the lesion; calculated as the angle of A* and B* in LAB* color space. Typical values range from 25 (red) to 75 (brown).+\n    'tbp_lv_Hext',                       # Hue outside lesion.+\n    'tbp_lv_L',                          # L inside lesion.+\n    'tbp_lv_Lext',                       # L outside lesion.+\n    'tbp_lv_areaMM2',                    # Area of lesion (mm^2).+\n    'tbp_lv_area_perim_ratio',           # Border jaggedness, the ratio between lesions perimeter and area. Circular lesions will have low values; irregular shaped lesions will have higher values. Values range 0-10.+\n    'tbp_lv_color_std_mean',             # Color irregularity, calculated as the variance of colors within the lesion's boundary.\n    'tbp_lv_deltaA',                     # Average A contrast (inside vs. outside lesion).+\n    'tbp_lv_deltaB',                     # Average B contrast (inside vs. outside lesion).+\n    'tbp_lv_deltaL',                     # Average L contrast (inside vs. outside lesion).+\n    'tbp_lv_deltaLB',                    #\n    'tbp_lv_deltaLBnorm',                # Contrast between the lesion and its immediate surrounding skin. Low contrast lesions tend to be faintly visible such as freckles; high contrast lesions tend to be those with darker pigment. Calculated as the average delta LB of the lesion relative to its immediate background in LAB* color space. Typical values range from 5.5 to 25.+\n    'tbp_lv_eccentricity',               # Eccentricity.+\n    'tbp_lv_minorAxisMM',                # Smallest lesion diameter (mm).+\n    'tbp_lv_nevi_confidence',            # Nevus confidence score (0-100 scale) is a convolutional neural network classifier estimated probability that the lesion is a nevus. The neural network was trained on approximately 57,000 lesions that were classified and labeled by a dermatologist.+,++\n    'tbp_lv_norm_border',                # Border irregularity (0-10 scale); the normalized average of border jaggedness and asymmetry.+\n    'tbp_lv_norm_color',                 # Color variation (0-10 scale); the normalized average of color asymmetry and color irregularity.+\n    'tbp_lv_perimeterMM',                # Perimeter of lesion (mm).+\n    'tbp_lv_radial_color_std_max',       # Color asymmetry, a measure of asymmetry of the spatial distribution of color within the lesion. This score is calculated by looking at the average standard deviation in LAB* color space within concentric rings originating from the lesion center. Values range 0-10.+\n    'tbp_lv_stdL',                       # Standard deviation of L inside  lesion.+\n    'tbp_lv_stdLExt',                    # Standard deviation of L outside lesion.+\n    'tbp_lv_symm_2axis',                 # Border asymmetry; a measure of asymmetry of the lesion's contour about an axis perpendicular to the lesion's most symmetric axis. Lesions with two axes of symmetry will therefore have low scores (more symmetric), while lesions with only one or zero axes of symmetry will have higher scores (less symmetric). This score is calculated by comparing opposite halves of the lesion contour over many degrees of rotation. The angle where the halves are most similar identifies the principal axis of symmetry, while the second axis of symmetry is perpendicular to the principal axis. Border asymmetry is reported as the asymmetry value about this second axis. Values range 0-10.+\n    'tbp_lv_symm_2axis_angle',           # Lesion border asymmetry angle.+\n    'tbp_lv_x',                          # X-coordinate of the lesion on 3D TBP.+\n    'tbp_lv_y',                          # Y-coordinate of the lesion on 3D TBP.+\n    'tbp_lv_z',                          # Z-coordinate of the lesion on 3D TBP.+\n]\n\nnew_num_cols = [\n    'lesion_size_ratio',                 # tbp_lv_minorAxisMM      / clin_size_long_diam_mm\n    'lesion_shape_index',                # tbp_lv_areaMM2          / tbp_lv_perimeterMM **2\n    'hue_contrast',                      # tbp_lv_H                - tbp_lv_Hext              abs\n    'luminance_contrast',                # tbp_lv_L                - tbp_lv_Lext              abs\n    'lesion_color_difference',           # tbp_lv_deltaA **2       + tbp_lv_deltaB **2 + tbp_lv_deltaL **2  sqrt  \n    'border_complexity',                 # tbp_lv_norm_border      + tbp_lv_symm_2axis\n    'color_uniformity',                  # tbp_lv_color_std_mean   / tbp_lv_radial_color_std_max\n\n    'position_distance_3d',              # tbp_lv_x **2 + tbp_lv_y **2 + tbp_lv_z **2  sqrt\n    'perimeter_to_area_ratio',           # tbp_lv_perimeterMM      / tbp_lv_areaMM2\n    'area_to_perimeter_ratio',           # tbp_lv_areaMM2          / tbp_lv_perimeterMM\n    'lesion_visibility_score',           # tbp_lv_deltaLBnorm      + tbp_lv_norm_color\n    'symmetry_border_consistency',       # tbp_lv_symm_2axis       * tbp_lv_norm_border\n    'consistency_symmetry_border',       # tbp_lv_symm_2axis       * tbp_lv_norm_border / (tbp_lv_symm_2axis + tbp_lv_norm_border)\n\n    'color_consistency',                 # tbp_lv_stdL             / tbp_lv_Lext\n    'consistency_color',                 # tbp_lv_stdL*tbp_lv_Lext / tbp_lv_stdL + tbp_lv_Lext\n    'size_age_interaction',              # clin_size_long_diam_mm  * age_approx\n    'hue_color_std_interaction',         # tbp_lv_H                * tbp_lv_color_std_mean\n    'lesion_severity_index',             # tbp_lv_norm_border      + tbp_lv_norm_color + tbp_lv_eccentricity / 3\n    'shape_complexity_index',            # border_complexity       + lesion_shape_index\n    'color_contrast_index',              # tbp_lv_deltaA + tbp_lv_deltaB + tbp_lv_deltaL + tbp_lv_deltaLBnorm\n\n    'log_lesion_area',                   # tbp_lv_areaMM2          + 1  np.log\n    'normalized_lesion_size',            # clin_size_long_diam_mm  / age_approx\n    'mean_hue_difference',               # tbp_lv_H                + tbp_lv_Hext    / 2\n    'std_dev_contrast',                  # tbp_lv_deltaA **2 + tbp_lv_deltaB **2 + tbp_lv_deltaL **2   / 3  np.sqrt\n    'color_shape_composite_index',       # tbp_lv_color_std_mean   + bp_lv_area_perim_ratio + tbp_lv_symm_2axis   / 3\n    'lesion_orientation_3d',             # tbp_lv_y                , tbp_lv_x  np.arctan2\n    'overall_color_difference',          # tbp_lv_deltaA           + tbp_lv_deltaB + tbp_lv_deltaL   / 3\n\n    'symmetry_perimeter_interaction',    # tbp_lv_symm_2axis       * tbp_lv_perimeterMM\n    'comprehensive_lesion_index',        # tbp_lv_area_perim_ratio + tbp_lv_eccentricity + bp_lv_norm_color + tbp_lv_symm_2axis   / 4\n    'color_variance_ratio',              # tbp_lv_color_std_mean   / tbp_lv_stdLExt\n    'border_color_interaction',          # tbp_lv_norm_border      * tbp_lv_norm_color\n    'border_color_interaction_2',\n    'size_color_contrast_ratio',         # clin_size_long_diam_mm  / tbp_lv_deltaLBnorm\n    'age_normalized_nevi_confidence',    # tbp_lv_nevi_confidence  / age_approx\n    'age_normalized_nevi_confidence_2',\n    'color_asymmetry_index',             # tbp_lv_symm_2axis       * tbp_lv_radial_color_std_max\n\n    'volume_approximation_3d',           # tbp_lv_areaMM2          * sqrt(tbp_lv_x**2 + tbp_lv_y**2 + tbp_lv_z**2)\n    'color_range',                       # abs(tbp_lv_L - tbp_lv_Lext) + abs(tbp_lv_A - tbp_lv_Aext) + abs(tbp_lv_B - tbp_lv_Bext)\n    'shape_color_consistency',           # tbp_lv_eccentricity     * tbp_lv_color_std_mean\n    'border_length_ratio',               # tbp_lv_perimeterMM      / pi * sqrt(tbp_lv_areaMM2 / pi)\n    'age_size_symmetry_index',           # age_approx              * clin_size_long_diam_mm * tbp_lv_symm_2axis\n    'index_age_size_symmetry',           # age_approx              * tbp_lv_areaMM2 * tbp_lv_symm_2axis\n]\n\ncat_cols = ['sex', 'anatom_site_general', 'tbp_tile_type', 'tbp_lv_location', 'tbp_lv_location_simple', 'attribution']\nnorm_cols = [f'{col}_patient_norm' for col in num_cols + new_num_cols]\nspecial_cols = ['count_per_patient']\nfeature_cols = num_cols + new_num_cols + cat_cols + norm_cols + special_cols\n\ndef read_data(path):\n    return (\n        pl.read_csv(path)\n        .with_columns(\n            pl.col('age_approx').cast(pl.String).replace('NA', np.nan).cast(pl.Float64),\n        )\n        .with_columns(\n            pl.col(pl.Float64).fill_nan(pl.col(pl.Float64).median()), # You may want to impute test data with train\n        )\n        .with_columns(\n            lesion_size_ratio              = pl.col('tbp_lv_minorAxisMM') / pl.col('clin_size_long_diam_mm'),\n            lesion_shape_index             = pl.col('tbp_lv_areaMM2') / (pl.col('tbp_lv_perimeterMM') ** 2),\n            hue_contrast                   = (pl.col('tbp_lv_H') - pl.col('tbp_lv_Hext')).abs(),\n            luminance_contrast             = (pl.col('tbp_lv_L') - pl.col('tbp_lv_Lext')).abs(),\n            lesion_color_difference        = (pl.col('tbp_lv_deltaA') ** 2 + pl.col('tbp_lv_deltaB') ** 2 + pl.col('tbp_lv_deltaL') ** 2).sqrt(),\n            border_complexity              = pl.col('tbp_lv_norm_border') + pl.col('tbp_lv_symm_2axis'),\n            color_uniformity               = pl.col('tbp_lv_color_std_mean') / (pl.col('tbp_lv_radial_color_std_max') + err),\n        )\n        .with_columns(\n            position_distance_3d           = (pl.col('tbp_lv_x') ** 2 + pl.col('tbp_lv_y') ** 2 + pl.col('tbp_lv_z') ** 2).sqrt(),\n            perimeter_to_area_ratio        = pl.col('tbp_lv_perimeterMM') / pl.col('tbp_lv_areaMM2'),\n            area_to_perimeter_ratio        = pl.col('tbp_lv_areaMM2') / pl.col('tbp_lv_perimeterMM'),\n            lesion_visibility_score        = pl.col('tbp_lv_deltaLBnorm') + pl.col('tbp_lv_norm_color'),\n            combined_anatomical_site       = pl.col('anatom_site_general') + '_' + pl.col('tbp_lv_location'),\n            symmetry_border_consistency    = pl.col('tbp_lv_symm_2axis') * pl.col('tbp_lv_norm_border'),\n            consistency_symmetry_border    = pl.col('tbp_lv_symm_2axis') * pl.col('tbp_lv_norm_border') / (pl.col('tbp_lv_symm_2axis') + pl.col('tbp_lv_norm_border')),\n        )\n        .with_columns(\n            color_consistency              = pl.col('tbp_lv_stdL') / pl.col('tbp_lv_Lext'),\n            consistency_color              = pl.col('tbp_lv_stdL') * pl.col('tbp_lv_Lext') / (pl.col('tbp_lv_stdL') + pl.col('tbp_lv_Lext')),\n            size_age_interaction           = pl.col('clin_size_long_diam_mm') * pl.col('age_approx'),\n            hue_color_std_interaction      = pl.col('tbp_lv_H') * pl.col('tbp_lv_color_std_mean'),\n            lesion_severity_index          = (pl.col('tbp_lv_norm_border') + pl.col('tbp_lv_norm_color') + pl.col('tbp_lv_eccentricity')) / 3,\n            shape_complexity_index         = pl.col('border_complexity') + pl.col('lesion_shape_index'),\n            color_contrast_index           = pl.col('tbp_lv_deltaA') + pl.col('tbp_lv_deltaB') + pl.col('tbp_lv_deltaL') + pl.col('tbp_lv_deltaLBnorm'),\n        )\n        .with_columns(\n            log_lesion_area                = (pl.col('tbp_lv_areaMM2') + 1).log(),\n            normalized_lesion_size         = pl.col('clin_size_long_diam_mm') / pl.col('age_approx'),\n            mean_hue_difference            = (pl.col('tbp_lv_H') + pl.col('tbp_lv_Hext')) / 2,\n            std_dev_contrast               = ((pl.col('tbp_lv_deltaA') ** 2 + pl.col('tbp_lv_deltaB') ** 2 + pl.col('tbp_lv_deltaL') ** 2) / 3).sqrt(),\n            color_shape_composite_index    = (pl.col('tbp_lv_color_std_mean') + pl.col('tbp_lv_area_perim_ratio') + pl.col('tbp_lv_symm_2axis')) / 3,\n            lesion_orientation_3d          = pl.arctan2(pl.col('tbp_lv_y'), pl.col('tbp_lv_x')),\n            overall_color_difference       = (pl.col('tbp_lv_deltaA') + pl.col('tbp_lv_deltaB') + pl.col('tbp_lv_deltaL')) / 3,\n        )\n        .with_columns(\n            symmetry_perimeter_interaction = pl.col('tbp_lv_symm_2axis') * pl.col('tbp_lv_perimeterMM'),\n            comprehensive_lesion_index     = (pl.col('tbp_lv_area_perim_ratio') + pl.col('tbp_lv_eccentricity') + pl.col('tbp_lv_norm_color') + pl.col('tbp_lv_symm_2axis')) / 4,\n            color_variance_ratio           = pl.col('tbp_lv_color_std_mean') / pl.col('tbp_lv_stdLExt'),\n            border_color_interaction       = pl.col('tbp_lv_norm_border') * pl.col('tbp_lv_norm_color'),\n            border_color_interaction_2     = pl.col('tbp_lv_norm_border') * pl.col('tbp_lv_norm_color') / (pl.col('tbp_lv_norm_border') + pl.col('tbp_lv_norm_color')),\n            size_color_contrast_ratio      = pl.col('clin_size_long_diam_mm') / pl.col('tbp_lv_deltaLBnorm'),\n            age_normalized_nevi_confidence = pl.col('tbp_lv_nevi_confidence') / pl.col('age_approx'),\n            age_normalized_nevi_confidence_2 = (pl.col('clin_size_long_diam_mm')**2 + pl.col('age_approx')**2).sqrt(),\n            color_asymmetry_index          = pl.col('tbp_lv_radial_color_std_max') * pl.col('tbp_lv_symm_2axis'),\n        )\n        .with_columns(\n            volume_approximation_3d        = pl.col('tbp_lv_areaMM2') * (pl.col('tbp_lv_x')**2 + pl.col('tbp_lv_y')**2 + pl.col('tbp_lv_z')**2).sqrt(),\n            color_range                    = (pl.col('tbp_lv_L') - pl.col('tbp_lv_Lext')).abs() + (pl.col('tbp_lv_A') - pl.col('tbp_lv_Aext')).abs() + (pl.col('tbp_lv_B') - pl.col('tbp_lv_Bext')).abs(),\n            shape_color_consistency        = pl.col('tbp_lv_eccentricity') * pl.col('tbp_lv_color_std_mean'),\n            border_length_ratio            = pl.col('tbp_lv_perimeterMM') / (2 * np.pi * (pl.col('tbp_lv_areaMM2') / np.pi).sqrt()),\n            age_size_symmetry_index        = pl.col('age_approx') * pl.col('clin_size_long_diam_mm') * pl.col('tbp_lv_symm_2axis'),\n            index_age_size_symmetry        = pl.col('age_approx') * pl.col('tbp_lv_areaMM2') * pl.col('tbp_lv_symm_2axis'),\n        )\n        .with_columns(\n            ((pl.col(col) - pl.col(col).mean().over('patient_id')) / (pl.col(col).std().over('patient_id') + err)).alias(f'{col}_patient_norm') for col in (num_cols + new_num_cols)\n        )\n        .with_columns(\n            count_per_patient = pl.col('isic_id').count().over('patient_id'),\n        )\n        .with_columns(\n            pl.col(cat_cols).cast(pl.Categorical),\n        )\n        .to_pandas()\n        .set_index(id_col)\n    )","metadata":{"execution":{"iopub.status.busy":"2024-08-29T09:24:51.361347Z","iopub.execute_input":"2024-08-29T09:24:51.362028Z","iopub.status.idle":"2024-08-29T09:24:51.402474Z","shell.execute_reply.started":"2024-08-29T09:24:51.361988Z","shell.execute_reply":"2024-08-29T09:24:51.401302Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"Read of train data","metadata":{}},{"cell_type":"code","source":"err = 1e-5\nid_col = 'isic_id'\nroot = Path('/kaggle/input/isic-2024-challenge')\n\ntrain_path = root / 'train-metadata.csv'\ntest_path = root / 'test-metadata.csv'\nsubm_path = root / 'sample_submission.csv'\n\ndf_train = pd.read_csv(\"/kaggle/input/df-train/df_train.csv\")\ndf_cleaned = read_data(train_path)\ndf_cleaned[\"pred\"] = df_train[\"pred\"].values","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-08-29T09:24:51.403677Z","iopub.execute_input":"2024-08-29T09:24:51.404163Z","iopub.status.idle":"2024-08-29T09:25:02.982436Z","shell.execute_reply.started":"2024-08-29T09:24:51.404119Z","shell.execute_reply":"2024-08-29T09:25:02.981639Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"Preprocessing of train data","metadata":{}},{"cell_type":"code","source":"def preprocess(df_cleaned):\n    mask = df_cleaned['anatom_site_general'].isna() & (df_cleaned['target'] != 1)\n    df_cleaned = df_cleaned[~mask]\n\n    mask = df_cleaned['sex'].isna() & (df_cleaned['target'] != 1)\n\n    # Drop rows based on the mask\n    df_cleaned = df_cleaned[~mask]\n\n    mask = df_cleaned['age_approx'].isna() & (df_cleaned['target'] != 1)\n    df_cleaned = df_cleaned[~mask]\n    df_cleaned[\"age_approx\"]= df_cleaned[\"age_approx\"].apply(lambda x: df_cleaned[\"age_approx\"].mean() if pd.isna(x) else x)\n    df_cleaned[\"sex\"] = df_cleaned[\"sex\"].apply(lambda x: 1 if pd.isna(x) else x)\n    df_cleaned[\"sex\"] = df_cleaned[\"sex\"].apply(lambda x:1 if x== \"male\" else 0)\n    df_cleaned[\"sex\"] = df_cleaned[\"sex\"].fillna(1).astype(int)\n    df_cleaned[\"tbp_tile_type\"] = df_cleaned[\"tbp_tile_type\"].apply(lambda x:1 if x== \"3D: white\" else 0).astype(float)\n    text_mapping = {\n        'posterior torso': 2,\n        'lower extremity': 0,\n        'anterior torso': 1,\n        'upper extremity': 3,\n        'head/neck': 4  # Assuming 0 if the count isn't provided or replace with actual count\n    }\n    df_cleaned['anatom_site_general'] = df_cleaned['anatom_site_general'].map(text_mapping)\n    df_cleaned['anatom_site_general'] = df_cleaned['anatom_site_general'].astype(float)\n    df_cleaned[\"sex\"]= df_cleaned[\"sex\"].astype(int)\n    y = df_cleaned['target']\n\n    del df_cleaned[\"tbp_lv_location_simple\"]\n    del df_cleaned[\"tbp_lv_location\"]\n    del df_cleaned[\"patient_id\"] \n    del df_cleaned[\"iddx_full\"]\n    del df_cleaned[\"attribution\"]\n    del df_cleaned[\"iddx_1\"]\n    del df_cleaned[\"image_type\"]\n    del df_cleaned[\"mel_mitotic_index\"] \n    del df_cleaned[\"target\"]\n    del df_cleaned[\"iddx_5\"]\n    del df_cleaned[\"iddx_4\"]\n    del df_cleaned[\"iddx_3\"]\n    del df_cleaned[\"iddx_2\"]\n    del df_cleaned[\"mel_thick_mm\"] \n    del df_cleaned[\"lesion_id\"] \n    del df_cleaned[\"copyright_license\"]\n    del df_cleaned[\"tbp_lv_dnn_lesion_confidence\"]\n    del df_cleaned[\"combined_anatomical_site\"]\n    df_cleaned.reset_index(drop=True, inplace=True)\n    \n    return df_cleaned\n\ndf_cleaned = preprocess(df_cleaned)","metadata":{"execution":{"iopub.status.busy":"2024-08-30T07:39:27.797031Z","iopub.execute_input":"2024-08-30T07:39:27.797326Z","iopub.status.idle":"2024-08-30T07:39:27.816229Z","shell.execute_reply.started":"2024-08-30T07:39:27.797292Z","shell.execute_reply":"2024-08-30T07:39:27.815207Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"LGB model on tabular data","metadata":{}},{"cell_type":"code","source":"# split the dataset into the training set and test set\n\nsampling_ratio = 0.01\nX = df_cleaned\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,shuffle=True, random_state = 0)\n\nlgb_params = {\n    'objective':        'binary',\n    'verbosity':        -1,\n    'n_iter':           200,\n    'boosting_type':    'gbdt',\n    'random_state':     42,\n    'lambda_l1':        0.08758718919397321, \n    'lambda_l2':        0.0039689175176025465, \n    'learning_rate':    0.03231007103195577, \n    'max_depth':        4, \n    'num_leaves':       103, \n    'colsample_bytree': 0.8329551585827726, \n    'colsample_bynode': 0.4025961355653304, \n    'bagging_fraction': 0.7738954452473223, \n    'bagging_freq':     4, \n    'min_data_in_leaf': 85, \n    'scale_pos_weight': 2.7984184778875543,\n}\n\nlgb_model = Pipeline([\n    ('sampler_1', RandomOverSampler(sampling_strategy= 0.003 , random_state=42)),\n    ('sampler_2', RandomUnderSampler(sampling_strategy=sampling_ratio, random_state=42)),\n    ('classifier', lgb.LGBMClassifier(**lgb_params)),\n])","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-08-29T09:25:04.584723Z","iopub.execute_input":"2024-08-29T09:25:04.585113Z","iopub.status.idle":"2024-08-29T09:25:08.333446Z","shell.execute_reply.started":"2024-08-29T09:25:04.585070Z","shell.execute_reply":"2024-08-29T09:25:08.332588Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"CB model on tabular data","metadata":{}},{"cell_type":"code","source":"sampling_ratio = 0.01\nX = df_cleaned\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,shuffle=True, random_state = 0)\n\ncb_params = {\n    'loss_function':     'Logloss',\n    'iterations':        250,\n    'verbose':           False,\n    'random_state':      42,\n    'max_depth':         7, \n    'learning_rate':     0.06936242010150652, \n    'scale_pos_weight':  2.6149345838209532, \n    'l2_leaf_reg':       6.216113851699493, \n    'subsample':         0.6249261779711819, \n    'min_data_in_leaf':  24\n}\ncb_model = Pipeline([\n    ('sampler_1', RandomOverSampler(sampling_strategy= 0.003 , random_state=42)),\n    ('sampler_2', RandomUnderSampler(sampling_strategy=sampling_ratio, random_state=42)),\n    ('classifier', cb.CatBoostClassifier(**cb_params)),\n])","metadata":{"execution":{"iopub.status.busy":"2024-08-29T09:25:08.334718Z","iopub.execute_input":"2024-08-29T09:25:08.335418Z","iopub.status.idle":"2024-08-29T09:25:08.862953Z","shell.execute_reply.started":"2024-08-29T09:25:08.335382Z","shell.execute_reply":"2024-08-29T09:25:08.862131Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"Stacking (Aggregating of 2 \"complex model\")","metadata":{}},{"cell_type":"code","source":"estimator = VotingClassifier([\n    ('lgb', lgb_model), ('cb', cb_model)             # ('xgb', xgb_model),\n], voting='soft',weights=[0.5,0.50])","metadata":{"execution":{"iopub.status.busy":"2024-08-29T09:25:08.864074Z","iopub.execute_input":"2024-08-29T09:25:08.864434Z","iopub.status.idle":"2024-08-29T09:25:08.869784Z","shell.execute_reply.started":"2024-08-29T09:25:08.864393Z","shell.execute_reply":"2024-08-29T09:25:08.868866Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"Fitting of models","metadata":{}},{"cell_type":"code","source":"lgb_model.fit(X_train, y_train)\ncb_model.fit(X_train, y_train)\nestimator.fit(X_train, y_train)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-08-29T09:25:08.873209Z","iopub.execute_input":"2024-08-29T09:25:08.873551Z","iopub.status.idle":"2024-08-29T09:26:12.386713Z","shell.execute_reply.started":"2024-08-29T09:25:08.873521Z","shell.execute_reply":"2024-08-29T09:26:12.385739Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"VotingClassifier(estimators=[('lgb',\n                              Pipeline(steps=[('sampler_1',\n                                               RandomOverSampler(random_state=42,\n                                                                 sampling_strategy=0.003)),\n                                              ('sampler_2',\n                                               RandomUnderSampler(random_state=42,\n                                                                  sampling_strategy=0.01)),\n                                              ('classifier',\n                                               LGBMClassifier(bagging_fraction=0.7738954452473223,\n                                                              bagging_freq=4,\n                                                              colsample_bynode=0.4025961355653304,\n                                                              colsample_bytree=0.8329551585827726,...\n                                                              objective='binary',\n                                                              random_state=42,\n                                                              scale_pos_weight=2.7984184778875543,\n                                                              verbosity=-1))])),\n                             ('cb',\n                              Pipeline(steps=[('sampler_1',\n                                               RandomOverSampler(random_state=42,\n                                                                 sampling_strategy=0.003)),\n                                              ('sampler_2',\n                                               RandomUnderSampler(random_state=42,\n                                                                  sampling_strategy=0.01)),\n                                              ('classifier',\n                                               <catboost.core.CatBoostClassifier object at 0x79e3f4eb81f0>)]))],\n                 voting='soft', weights=[0.5, 0.5])","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;lgb&#x27;,\n                              Pipeline(steps=[(&#x27;sampler_1&#x27;,\n                                               RandomOverSampler(random_state=42,\n                                                                 sampling_strategy=0.003)),\n                                              (&#x27;sampler_2&#x27;,\n                                               RandomUnderSampler(random_state=42,\n                                                                  sampling_strategy=0.01)),\n                                              (&#x27;classifier&#x27;,\n                                               LGBMClassifier(bagging_fraction=0.7738954452473223,\n                                                              bagging_freq=4,\n                                                              colsample_bynode=0.4025961355653304,\n                                                              colsample_bytree=0.8329551585827726,...\n                                                              objective=&#x27;binary&#x27;,\n                                                              random_state=42,\n                                                              scale_pos_weight=2.7984184778875543,\n                                                              verbosity=-1))])),\n                             (&#x27;cb&#x27;,\n                              Pipeline(steps=[(&#x27;sampler_1&#x27;,\n                                               RandomOverSampler(random_state=42,\n                                                                 sampling_strategy=0.003)),\n                                              (&#x27;sampler_2&#x27;,\n                                               RandomUnderSampler(random_state=42,\n                                                                  sampling_strategy=0.01)),\n                                              (&#x27;classifier&#x27;,\n                                               &lt;catboost.core.CatBoostClassifier object at 0x79e3f4eb81f0&gt;)]))],\n                 voting=&#x27;soft&#x27;, weights=[0.5, 0.5])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;lgb&#x27;,\n                              Pipeline(steps=[(&#x27;sampler_1&#x27;,\n                                               RandomOverSampler(random_state=42,\n                                                                 sampling_strategy=0.003)),\n                                              (&#x27;sampler_2&#x27;,\n                                               RandomUnderSampler(random_state=42,\n                                                                  sampling_strategy=0.01)),\n                                              (&#x27;classifier&#x27;,\n                                               LGBMClassifier(bagging_fraction=0.7738954452473223,\n                                                              bagging_freq=4,\n                                                              colsample_bynode=0.4025961355653304,\n                                                              colsample_bytree=0.8329551585827726,...\n                                                              objective=&#x27;binary&#x27;,\n                                                              random_state=42,\n                                                              scale_pos_weight=2.7984184778875543,\n                                                              verbosity=-1))])),\n                             (&#x27;cb&#x27;,\n                              Pipeline(steps=[(&#x27;sampler_1&#x27;,\n                                               RandomOverSampler(random_state=42,\n                                                                 sampling_strategy=0.003)),\n                                              (&#x27;sampler_2&#x27;,\n                                               RandomUnderSampler(random_state=42,\n                                                                  sampling_strategy=0.01)),\n                                              (&#x27;classifier&#x27;,\n                                               &lt;catboost.core.CatBoostClassifier object at 0x79e3f4eb81f0&gt;)]))],\n                 voting=&#x27;soft&#x27;, weights=[0.5, 0.5])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lgb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomOverSampler</label><div class=\"sk-toggleable__content\"><pre>RandomOverSampler(random_state=42, sampling_strategy=0.003)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomUnderSampler</label><div class=\"sk-toggleable__content\"><pre>RandomUnderSampler(random_state=42, sampling_strategy=0.01)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(bagging_fraction=0.7738954452473223, bagging_freq=4,\n               colsample_bynode=0.4025961355653304,\n               colsample_bytree=0.8329551585827726,\n               lambda_l1=0.08758718919397321, lambda_l2=0.0039689175176025465,\n               learning_rate=0.03231007103195577, max_depth=4,\n               min_data_in_leaf=85, n_iter=200, num_leaves=103,\n               objective=&#x27;binary&#x27;, random_state=42,\n               scale_pos_weight=2.7984184778875543, verbosity=-1)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>cb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomOverSampler</label><div class=\"sk-toggleable__content\"><pre>RandomOverSampler(random_state=42, sampling_strategy=0.003)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomUnderSampler</label><div class=\"sk-toggleable__content\"><pre>RandomUnderSampler(random_state=42, sampling_strategy=0.01)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CatBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;catboost.core.CatBoostClassifier object at 0x79e3f4eb81f0&gt;</pre></div></div></div></div></div></div></div></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Feature importance LGB model","metadata":{}},{"cell_type":"code","source":"# Extract the fitted model from the pipeline\nmodel = lgb_model.named_steps['classifier']\n\n# Get feature importance scores\nfeature_importances = model.feature_importances_\n\n# Create a DataFrame to hold feature names and their importance\nimportance_df = pd.DataFrame({\n    'Feature': X_train.columns,\n    'Importance': feature_importances\n})\n\n# Sort the DataFrame by importance\nimportance_df = importance_df.sort_values(by='Importance', ascending=False)\n\nprint(\"Feature Importances:\")\nprint(importance_df)","metadata":{"execution":{"iopub.status.busy":"2024-08-29T09:26:12.387776Z","iopub.execute_input":"2024-08-29T09:26:12.388112Z","iopub.status.idle":"2024-08-29T09:26:12.403046Z","shell.execute_reply.started":"2024-08-29T09:26:12.388079Z","shell.execute_reply":"2024-08-29T09:26:12.402082Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Feature Importances:\n                                           Feature  Importance\n156                                           pred          96\n155                              count_per_patient          82\n147  age_normalized_nevi_confidence_2_patient_norm          82\n79                         age_approx_patient_norm          75\n71                age_normalized_nevi_confidence_2          69\n..                                             ...         ...\n131            shape_complexity_index_patient_norm           2\n29                     tbp_lv_radial_color_std_max           2\n27                               tbp_lv_norm_color           1\n17                           tbp_lv_color_std_mean           1\n1                                              sex           0\n\n[157 rows x 2 columns]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Feature importance CB model","metadata":{}},{"cell_type":"code","source":"# Extract the fitted model from the pipeline\nmodel = lgb_model.named_steps['classifier']\n\n# Get feature importance scores\nfeature_importances = model.feature_importances_\n\n# Create a DataFrame to hold feature names and their importance\nimportance_df = pd.DataFrame({\n    'Feature': X_train.columns,\n    'Importance': feature_importances\n})\n\n# Sort the DataFrame by importance\nimportance_df = importance_df.sort_values(by='Importance', ascending=False)\n\nprint(\"Feature Importances:\")\nprint(importance_df)","metadata":{"execution":{"iopub.status.busy":"2024-08-29T09:26:12.404472Z","iopub.execute_input":"2024-08-29T09:26:12.404778Z","iopub.status.idle":"2024-08-29T09:26:12.414854Z","shell.execute_reply.started":"2024-08-29T09:26:12.404746Z","shell.execute_reply":"2024-08-29T09:26:12.413963Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Feature Importances:\n                                           Feature  Importance\n156                                           pred          96\n155                              count_per_patient          82\n147  age_normalized_nevi_confidence_2_patient_norm          82\n79                         age_approx_patient_norm          75\n71                age_normalized_nevi_confidence_2          69\n..                                             ...         ...\n131            shape_complexity_index_patient_norm           2\n29                     tbp_lv_radial_color_std_max           2\n27                               tbp_lv_norm_color           1\n17                           tbp_lv_color_std_mean           1\n1                                              sex           0\n\n[157 rows x 2 columns]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Evaluation on df_train of model","metadata":{}},{"cell_type":"code","source":"y_pred_proba = estimator.predict_proba(X_test)[:, 1]\ndef score(solution: np.array, submission: np.array, min_tpr: float=0.80) -> float:\n\n    # rescale the target. set 0s to 1s and 1s to 0s (since sklearn only has max_fpr)\n    v_gt = abs(solution-1)\n    v_pred = -1.0 * submission\n\n    max_fpr = abs(1-min_tpr)\n\n    # using sklearn.metric functions: (1) roc_curve and (2) auc\n    fpr, tpr, _ = roc_curve(v_gt, v_pred, sample_weight=None)\n    if max_fpr is None or max_fpr == 1:\n        return auc(fpr, tpr)\n    if max_fpr <= 0 or max_fpr > 1:\n        raise ValueError(\"Expected min_tpr in range [0, 1), got: %r\" % min_tpr)\n        \n    # Add a single point at max_fpr by linear interpolation\n    stop = np.searchsorted(fpr, max_fpr, \"right\")\n    x_interp = [fpr[stop - 1], fpr[stop]]\n    y_interp = [tpr[stop - 1], tpr[stop]]\n    tpr = np.append(tpr[:stop], np.interp(max_fpr, x_interp, y_interp))\n    fpr = np.append(fpr[:stop], max_fpr)\n    partial_auc = auc(fpr, tpr)\n    \n    return partial_auc\n\n#print(f\"Accuracy of the model: {100 * correct // total} %\")\nprint(f\"AUC of the model: {score(np.array(y_test), np.array(y_pred_proba), min_tpr=0.0)}\")\nprint(f\"pAUC-TPR(0.8) of the model: {score(np.array(y_test), np.array(y_pred_proba))}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-29T09:26:12.416076Z","iopub.execute_input":"2024-08-29T09:26:12.416359Z","iopub.status.idle":"2024-08-29T09:26:13.135957Z","shell.execute_reply.started":"2024-08-29T09:26:12.416328Z","shell.execute_reply":"2024-08-29T09:26:13.134851Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"AUC of the model: 0.9628906904530173\npAUC-TPR(0.8) of the model: 0.16886259033073434\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"markdown","source":"Read of test data","metadata":{}},{"cell_type":"code","source":"err = 1e-5\nid_col = 'isic_id'\nroot = Path('/kaggle/input/isic-2024-challenge')\n\ntrain_path = root / 'train-metadata.csv'\ntest_path = root / 'test-metadata.csv'\n\ndf_sub = read_data(test_path)\ndf_sub[\"pred\"] = df_test[\"pred\"].values","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-08-29T09:26:13.137578Z","iopub.execute_input":"2024-08-29T09:26:13.138193Z","iopub.status.idle":"2024-08-29T09:26:13.171200Z","shell.execute_reply.started":"2024-08-29T09:26:13.138148Z","shell.execute_reply":"2024-08-29T09:26:13.170200Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"Preprocessing of test data","metadata":{}},{"cell_type":"code","source":"del df_sub[\"tbp_lv_location_simple\"]\ndel df_sub[\"tbp_lv_location\"]\ndel df_sub[\"patient_id\"] \ndel df_sub[\"attribution\"]\ndel df_sub[\"image_type\"]\ndel df_sub[\"combined_anatomical_site\"]\ndel df_sub[\"copyright_license\"]\ndf_sub.reset_index(drop=True, inplace=True)\ndf_sub[\"age_approx\"]= df_cleaned2[\"age_approx\"].apply(lambda x: df_cleaned[\"age_approx\"].mean() if pd.isna(x) else x)\ndf_sub[\"sex\"] = df_cleaned2[\"sex\"].apply(lambda x: 1 if pd.isna(x) else x)\ndf_sub[\"sex\"] = df_cleaned2[\"sex\"].apply(lambda x:1 if x== \"male\" else 0)\ndf_sub[\"tbp_tile_type\"] = df_cleaned2[\"tbp_tile_type\"].apply(lambda x:1 if x== \"3D: white\" else 0).astype(float)\ntext_mapping = {\n    'posterior torso': 2,\n    'lower extremity': 0,\n    'anterior torso': 1,\n    'upper extremity': 3,\n    'head/neck': 4\n}\ndf_sub['anatom_site_general'] = df_sub['anatom_site_general'].map(text_mapping).astype(float)\ndf_sub[\"sex\"]= df_sub[\"sex\"].astype(int)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-08-29T09:26:13.172551Z","iopub.execute_input":"2024-08-29T09:26:13.173240Z","iopub.status.idle":"2024-08-29T09:26:13.189960Z","shell.execute_reply.started":"2024-08-29T09:26:13.173193Z","shell.execute_reply":"2024-08-29T09:26:13.189156Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"Prediction on test data","metadata":{}},{"cell_type":"code","source":"y_pred_proba = estimator.predict_proba(df_sub)\ny_pred_proba = y_pred_proba[:,1]\nsubmission = pd.DataFrame()\nsubmission[\"isic_id\"] = df_test[\"isic_id\"]\nsubmission[\"target\"] = y_pred_proba\nsubmission.to_csv('submission.csv', index=False)\nsubmission","metadata":{"execution":{"iopub.status.busy":"2024-08-29T09:26:13.191041Z","iopub.execute_input":"2024-08-29T09:26:13.191330Z","iopub.status.idle":"2024-08-29T09:26:13.227991Z","shell.execute_reply.started":"2024-08-29T09:26:13.191300Z","shell.execute_reply":"2024-08-29T09:26:13.227044Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"        isic_id    target\n0  ISIC_0015657  0.263240\n1  ISIC_0015729  0.341653\n2  ISIC_0015740  0.511797","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>isic_id</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ISIC_0015657</td>\n      <td>0.263240</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ISIC_0015729</td>\n      <td>0.341653</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ISIC_0015740</td>\n      <td>0.511797</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]}]}